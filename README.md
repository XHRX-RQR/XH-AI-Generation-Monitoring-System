# 此仓库正在被审核，仅LinuxDo邀请人可见
# XH AI Generation Monitoring System

> 基于大语言模型的多轮对话式 AI 生成内容检测系统，采用法语言学分析方法实现高精度判别。

## 项目概述

XH AI Generation Monitoring System 是一个智能文本分析平台，用于判断给定文本是由人类撰写还是由 AI 模型生成。系统通过精心设计的**三轮递进式法语言学分析流水线**，从表层特征提取逐步深入到微观模式探测，最终进行证据综合研判，实现高置信度的 AI 内容检测。

### 核心能力

- **三轮递进式深度分析** — 覆盖 9 个语言学维度的渐进检测流水线
- **OpenAI 兼容接口** — 支持任何暴露 `/v1/chat/completions` 端点的 API 服务商
- **双主题界面** — 极简黑白风格，支持深色/浅色模式切换，保留功能性彩色标注
- **多语言检测** — 支持中文、英文及其他语种的文本分析
- **90%+ 准确率** — 在包含 10 个多样化样本的基准测试集上验证通过

## 系统架构

```
┌──────────────────────────────────────────────────────┐
│                  浏览器（前端）                         │
│     HTML / CSS / JavaScript — 双主题极简界面            │
└─────────────────────┬────────────────────────────────┘
                      │ HTTP POST /api/detect
┌─────────────────────▼────────────────────────────────┐
│              Flask 后端 (server.py)                    │
│           请求校验 · 响应组装 · 错误处理                  │
└─────────────────────┬────────────────────────────────┘
                      │
┌─────────────────────▼────────────────────────────────┐
│            检测引擎 (detector.py)                      │
│       三轮流水线编排 · 响应解析 · 结果聚合                 │
└─────────────────────┬────────────────────────────────┘
                      │ 3 次 API 调用
┌─────────────────────▼────────────────────────────────┐
│           提示词工程 (prompts.py)                      │
│       法语言学系统提示词 · 三轮对话模板                    │
└─────────────────────┬────────────────────────────────┘
                      │
┌─────────────────────▼────────────────────────────────┐
│       OpenAI 兼容大语言模型 API（外部服务）                │
│     GPT-4o / GPT-5 / Claude / DeepSeek 等             │
└──────────────────────────────────────────────────────┘
```

## 检测流水线

系统依次执行三轮分析，每轮基于前一轮的结果进行更深层次的推理：

### 第一轮 — 特征提取

对五个核心语言学维度进行 0–10 分评分：

| 维度 | 检测内容 |
|---|---|
| **词汇多样性** | 类符/形符比、词汇复杂度、重复性短语模式 |
| **句式突变性** | 句长方差、句法多样性、平行结构滥用程度 |
| **篇章组织模式** | 段落均匀度、过渡词滥用、公式化结构 |
| **内容语义** | 模糊限定词频率、个人声音、细节具体性、自然错误 |
| **风格一致性** | 语气稳定性、全文质量均匀度 |

### 第二轮 — 深度模式分析

对四个高区分度维度进行精细探测：

| 维度 | 检测内容 |
|---|---|
| **微观模式** | 句首词多样性、连词使用模式、标点规律性 |
| **语义深度** | 论断-证据比、逻辑流可预测性、情感真实性 |
| **语言指纹** | 个人语言习惯标记、语域切换、文化/时间线索 |
| **AI 特征标记** | 模型特征短语（GPT 风格、Claude 风格）、结构性模式 |

### 第三轮 — 证据综合研判

基于加权证据框架合并所有分析结果，输出最终判定：

**证据权重分配：**

| 权重等级 | 对应特征 |
|---|---|
| **高权重** | 句式突变性、个人声音与具体性、微观模式多样性、情感真实性 |
| **中权重** | 词汇多样性、篇章组织模式、标点多样性、语域切换 |
| **低权重** | 语法质量、主题覆盖度、单一维度的词汇复杂度 |

**置信度校准标准：**

| 置信度范围 | 含义 |
|---|---|
| 90–100% | 多个强独立指标方向一致 |
| 70–89% | 大部分指标一致，部分存在歧义 |
| 50–69% | 信号混杂，AI 与人类特征交织 |
| < 50% | 证据不足，无法做出可靠判定 |

## 项目结构

```
.
├── server.py            # Flask 后端 — 路由与 API 端点
├── detector.py          # 检测引擎 — 三轮流水线编排
├── prompts.py           # 提示词工程 — 法语言学系统提示词
├── requirements.txt     # Python 依赖
├── test_accuracy.py     # 自动化准确率测试套件（10 个样本）
├── test_results.json    # 最近一次测试运行结果
├── templates/
│   └── index.html       # 前端 HTML
└── static/
    ├── style.css        # 双主题样式表（深色 + 浅色）
    └── script.js        # 前端逻辑与主题切换
```

## 快速开始

### 前置条件

- Python 3.9+
- 一个可用的 OpenAI 兼容 API 端点及有效的 API 密钥

### 安装
>先拷贝文件，并在文件目录打开终端

```bash

pip install -r requirements.txt
```

### 启动

```bash
python server.py
```

服务默认运行在 `http://localhost:8765`。可通过环境变量 `PORT` 覆盖端口：

```bash
PORT=3000 python server.py
```

### 配置

1. 在浏览器中打开 `http://localhost:8765`
2. 点击右上角 **齿轮图标** 打开设置弹窗
3. 填入 API 地址、API 密钥和模型名称
4. 点击 **保存** — 配置将持久化存储于浏览器 `localStorage`

## API 接口文档

### `POST /api/detect`

提交文本进行 AI 内容检测。

**请求体**

```json
{
  "text": "待检测的文本内容...",
  "api_base": "https://api.openai.com/v1",
  "api_key": "sk-...",
  "model": "gpt-4o",
  "temperature": 0.1
}
```

| 参数 | 类型 | 必填 | 说明 |
|---|---|---|---|
| `text` | string | 是 | 待检测文本，不少于 50 个字符 |
| `api_base` | string | 是 | OpenAI 兼容 API 的基础地址 |
| `api_key` | string | 是 | API 认证密钥 |
| `model` | string | 是 | 模型名称，如 `gpt-4o`、`gpt-5` |
| `temperature` | float | 否 | 生成温度，默认 `0.1`，建议保持低值以获得稳定结果 |

**成功响应** `200`

```json
{
  "success": true,
  "result": {
    "verdict": "AI-generated",
    "confidence": 92,
    "ai_probability": 94,
    "summary": "文本呈现高概括、低可核验细节的安全型概述风格...",
    "key_indicators": [
      {
        "feature": "句式突变性",
        "signal": "AI",
        "strength": "Strong",
        "detail": "句长高度均匀，缺少短句插入与自我修正..."
      }
    ],
    "caveats": ["文本较短，统计证据有限。"],
    "analysis_rounds": {
      "round1_features": { "..." : "..." },
      "round2_deep_analysis": { "..." : "..." }
    },
    "elapsed_seconds": 42.5,
    "text_length": 435,
    "model_used": "gpt-4o"
  }
}
```

**错误响应** `422`

```json
{
  "error": "API request timed out. Please check your API endpoint."
}
```

### `GET /api/health`

健康检查端点。返回 `{"status": "ok"}`。

## 测试

项目包含一个自动化准确率测试套件，涵盖 10 个多样化样本（5 个人类撰写 + 5 个 AI 生成）：

```bash
python test_accuracy.py
```

### 测试样本分类

| 编号 | 类别 | 预期标签 | 文本风格 |
|---|---|---|---|
| 1 | 个人博客 / 回忆录 | 人类撰写 | 随性叙事，带有怀旧情感 |
| 2 | Reddit / 论坛帖子 | 人类撰写 | 非正式，碎片化表达 |
| 3 | 医学病历笔记 | 人类撰写 | 专业用语夹杂个人声音 |
| 4 | 中文个人散文 | 人类撰写 | 母语中文，感悟性表达 |
| 5 | 技术观点博客 | 人类撰写 | 强烈个人立场与情绪 |
| 6 | AI 通用概述文章 | AI 生成 | 典型 LLM 概述风格 |
| 7 | 建议类文章 | AI 生成 | 公式化自助文体 |
| 8 | 历史知识总结 | AI 生成 | 百科式平衡叙述 |
| 9 | 气候变化论述 | AI 生成 | 结构化政策概述 |
| 10 | Python 语言介绍 | AI 生成 | 技术推广文案 |

### 最新测试结果

```
总计样本数：  10
正确判定数：  9 / 10
准确率：      90.0%

人类撰写样本：4/5 正确（1 例医学笔记判定为"无法确定"）
AI 生成样本： 5/5 全部正确
```

## 前端功能

### 双主题模式

点击顶部栏的太阳/月亮图标即可在深色和浅色模式之间切换。主题偏好保存在 `localStorage` 中，刷新后自动恢复。

| 元素 | 深色模式 | 浅色模式 |
|---|---|---|
| 背景 | `#000` 纯黑 | `#f8f8f8` 浅灰白 |
| 卡片 | `#111` 深灰 | `#fff` 纯白 |
| 主按钮 | 白底黑字 | 黑底白字 |
| 正文 | `#e5e5e5` 浅灰 | `#111` 近黑 |

### 功能性彩色标注

在两种主题下均保留以下状态色：

| 颜色 | 语义 |
|---|---|
| `#ef4444` 红色 | AI 生成信号 |
| `#22c55e` 绿色 | 人类撰写信号 |
| `#eab308` 黄色 | 无法确定 / 警告 / 注意事项 |

### 设置弹窗

API 配置通过居中模态弹窗完成（点击齿轮图标触发），主界面仅保留文本输入与检测操作，保持界面简洁高效。支持点击遮罩层关闭、`Esc` 键关闭等交互方式。

## 技术说明

### API 兼容性策略

系统采用**纯文本标签式输出**（`LABEL: value`）而非 JSON 格式，以最大化对不同 LLM 服务商的兼容性。部分 API 代理会剥离 JSON 格式字符（冒号、引号等），标签式格式对此类转换具有天然鲁棒性。

### 提示词工程设计

每轮分析的系统提示词均编码了法语言学领域的专业知识：

- **特征定义** — 基于已建立的文体计量学（Stylometry）研究文献
- **评分标尺** — 提供校准的 0–10 分量表，附带锚定描述
- **证据加权** — 第三轮的权重分配反映了各特征经验验证的区分效力
- **混淆因素感知** — 主动识别专业编辑润色、非母语写作、学术体裁等可能导致误判的情形

### 已知局限性

- **短文本**（< 200 字符）因统计证据有限，检测置信度较低
- **经过深度人工编辑的 AI 文本**可能呈现人类写作特征而规避检测
- **高度正式的人类写作**（学术论文、法律文书等）可能触发误报
- **检测质量取决于底层 LLM 的能力** — 更强的模型能产出更准确的分析
- **每次检测需 3 次 API 调用**，影响响应延迟与调用成本

## 依赖

| 依赖包 | 版本要求 | 用途 |
|---|---|---|
| Flask | >= 2.3.0 | Web 服务器与 API 路由 |
| Requests | >= 2.31.0 | LLM API 的 HTTP 客户端 |

## 许可证

MIT
